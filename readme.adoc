= EDA Merging Service
:toc: left
:source-highlighter: pygments
:icons: font
// Github specifics
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

== Purpose

The EDA Merging Service plays the role in the greater EDA service system of merging single-entity
tabular data streams received from the Subsetting and Compute services into a single tabular stream,
which still represents a single entity, but which has gathered into it data from potentially many
other entities.  It also is responsible for the creation of Derived Variable data, which is generated
using these merged streams.

== Ways Data Can Be Merged

=== Native Variables

"Native" is a term used to define variables that belong to the entity in hand in the original study
data (i.e. loaded into the database or study files), to differentiate them from variables generated
or gathered through the means below.  The subsetting service provides these variables in its tabular
responses.

=== Inherited Variables

The most basic way data can be merged is through inherited variables.  The entity tree is organized
in a way such that, as you descend from the root entity, all children have a one-to-one or
many-to-one relationship with their parent.  This remains true with the application of subset
filters, as long as the same filters are applied to both entities during Subsetting Service requests.

Because of this, a record of a child entity has a unique parent ID, and a row for that ID is
guaranteed to be present in a parent entity stream of the same subset as the child.  Thus, one
can apply a parent's data to a child in a single pass of both streams by adding selected parent
variables to the tabular row of the child's stream.  This is what the merging service does and is
known as "inheriting" an ancestor entity's data.

=== Computed Variables

The EDA Compute Service asynchonously produces tabular data streams representing data for a single
entity.  These streams contain newly computed variables, which can be merged into a tabular data
stream by the Merging Service.  Typically the computed variables' entity matches the target entity
of the Merging service request; however, computed variables can be applied to any descendant
entity of the computed variable entity through inheritance (see above).

=== Derived Variables

Derived Variables are variables that are created in the Merging Service by plugins.  Additional
plugins can be written against a flexible Java API.  The input to these plugins is a specification
object whose schema is defined by the plugin.  Using the specification object, a plugin declares a
set of tabular streams it requires to generated the derived data.  These streams of data are fetched
from the Subsetting Service and, row-by-row, the plugin is applied to calculate new values.  Some
variable metadata is also produced by the plugin (any that can be produced without actually visiting
the data) but other variable metadata (e.g. num unique values) must be generated elsewhere.

There are two types of Derived Variables:

==== Transforms

Transforms are Derived Variables that take one or more variables on a single entity (or inherited
from an ancestor) and use their values to produce a new variable on the same entity.  An example of
this might be numeric addition, where the value of a new variable A is produced by adding the values
of B and C (B + C), where B and C are existing variables on the same entity or an ancestor.

==== Reductions

Reductions are Derived Variables that take one or more variables from multiple rows of a descendant
entity and functionally reduce them to a single value (i.e. iterate over them, applying a reduction
function to a row and some intermediate values).  An example of this might be to take a numeric
average or mean: if entity X is a parent of entity Y, and A is a varible of entity Y, then a plugin
could produce a new variable B on X whose value is the mean of A over Y's child rows of a single
row of X.

== Design

=== The Request

A merged tabular request consists of the following elements:

. Study ID: each request is based on a single study
. Entity ID: the entity of the response; the response will return one row for each record of this entity in the primary subset
. Output Variables: a list of variable spec objects (entity ID + variable ID); each of these will be a column in the tabular response
. Subset Filters (optional): list of objects, each of which describes a filter; together they define the primary request subset
. Compute Spec (optional): a compute plugin name and configuration which should be used to pull in computed variables
. Derived Variable Specs (optional): list of objects, each of which describes how to create a new derived variable

=== Preprocessing

Before generating the response, the merging service gathers required resources.  These include:
. Pulling out the elements of the request and saving them off
. Subsetting and Compute Service Clients: Objects that make it easy to request data from these services
. Study Metadata: Use the study ID in the request to ask Subsetting for the study's metadata
. Derived Variable Factory: An object configured with the incoming derived variable specs which can produce dependency-ordered, configured plugin instances
. Computed Variable Metadata: Use the passed compute spec to ensure the compute job is complete and request and save off computed variable metadata

EDA Common's ReferenceMetadata class is the container for entity and variable metadata for a
single study, and after construction, contains the variables 

=== Processing

==== Building an entity stream processing tree

The first step in creating the merged response is to build a tree of nodes through which the data
will flow.  Each node will process an incoming tabular stream from the subsetting or compute
services, and thus each node represents an entity in the study's entity tree.  However, the tree
of processing nodes is not the same shape or size as the study's entity tree.

The root node of of the procecessing tree will process a stream of the request's target entity,
and is tasked with providing the requested output variables.  The requested output variables for
any node, including the root, can only belong to that node's entity, or to an ancestor.  The
root node is also responsible for adding computed vars, which can also belong only to the root
node's entity or to an ancestor.

Any native or transform variables of the requested entity will be added to the result in the root
node.  Its children will fit into one of two categories:

. Processing nodes representing ancestor entities, from which variables can be inherited.
. Processing nodes representing descendant entities, from which variables can be reduced.  This
  case only applies when a reduction derived variable is needed on the parent node.

Each of the child nodes (representing an ancestor or descendant entity) is tasked with providing
a set of requested output variables as well, assigned by the parent node.  In the case of ancestor
entity nodes, these will be those variables requested of the root (or required by a transform)
that natively belong to the ancestor, and will be inherited.  In the case of descendant entity
nodes, these will be those variables required by a reduction derived variable on the root node.

If the child nodes of the root are asked to provide varibles which are themselves reductions,
transforms that require inherited varibles, or even more richly nested variable dependencies,
the child nodes may create their own child nodes to serve this data, recursively, until only
native variables are needed.

This means there may be multiple streams or the same entity, with the same subset, perhaps even
with the same variables, requested of subsetting, but this is necessary because the processing
tree will process those streams at different rates and at different locations in the processing
tree.

Computed variables are brought in on a single stream (only one compute's tabular result can
be merged per request), and the computed entity must be the same as, or an ancestor of, the
request's target entity.  This stream is treated as a special sibling stream to the target entity,
or as a regular ancestor stream.

==== Requesting and Distributing Tabular Data Streams

Once the processing tree has been created, it is asked to provide a set of StreamSpec objects,
each of which is either the (singular) request to the compute service, or defines a request to
be passed to the subsetting service.  StreamSpecs contain:

. ID (name) of the stream
. Required entity ID
. IDs of required variables
. Subset filters (some derived variable plugins may override the primary subset)

Each node in the tree defines a StreamSpec for the tabular stream it will process.  Each
StreamSpec is used to create a request to the tabular endpoints in subsetting or compute services,
which return a binary data stream.  These requests are made in parallel and their responses
are collected into a map from stream ID (name) to InputStream.

If only a single stream is required (meaning the tree is only a single node), and no operations
need to be performed on the data (i.e. no transform derived vars), then the processing tree
is bypassed and the stream is transferred directly as the tabular response (with rewritten
headers; see below).

Otherwise, the InputStream map is passed to the processing tree, where each node claims the
InputStream associated with its StreamSpec.  The tree is now ready to deliver data.

==== Streaming the Merged Data

Each node in the processing tree is an iterator over a Map<String,String> containing the data
for a single row (key is dot-notated variable spec).  This includes the root node, which is
specially built to return a row with only the variables asked for in the original request, and
in the order they were requested.

To produce its row, each node, including the root, firs reads the row of native variables of its
entity.  It then inherits any variables produced by its child nodes which represent ancestor
entities.  Then it executes any configured reduction derived variables it needs by iterating
over the rows in its child nodes which represent descendant entites.  Finally, it executes any
configured transform derived variable plugins to create the remaining values.  Its list of
derived variable instances is pre-ordered by dependency so that any transform value is computed
only after its dependencies are computed.  Circular dependencies are checked in advance and
throw a 400.

Once a node has produced all the variable values requested of it, it returns the output Map
for that row from its `next()` method, and its parent node, or the response formatter,
consumes the row.

=== A Note About Headers

The header line of the merging service's tabular response consists of an ID column for the target
entity and each of its ancestors (in that order, up the tree), data columns for each of the
requested output variables, and columns for any computed variables generated by the specified
compute job.

The format of the header is different for incoming vs outgoing streams.  Because the compute and
subsetting services serve tabular responses for a single entity, their headers consist of only the
variable ID (no entity IDs).  However, a merging tabular response could have columns for multiple
entities (via inheritance), so they are encoded in the format "${entity_id}.${variable_id}".  ID
columns in merging responses use the entity ID they are the primary key for (e.g. even though a
participant record has a household ID, the household ID column's header will be household.household_id,
not participant.household_id.
